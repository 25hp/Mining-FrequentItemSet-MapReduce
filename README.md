# Map-Reduce
A Map Reduce algorithm using Apache Spark (PySpark) for finding average rating of  each movie and tag by the user. 

It makes use of Resilient distributed dataset (RDD)  for  collection of data.

It uses Pythons Lambda syntax.

Dataset: https://grouplens.org/datasets/movielens/

There are two tasks:

Task 1 :

Calculate each movies average rating using rating.csv.

Task 2: 

Calculate average rating of each tag using rating.csv and tags.csv

# Park-Chen-Yu-Algorithm

It is a PCY Algorithm implementation which finds frequent itemsets(pairs) in sample input data. 

It is hash-based algorithm implemented using Apache Spark ( PySpark).

It uses Resilient Distributed Dataset (RDD), implementing the algorithm in Python's lambda syntax.



# Refer


For Python Lambda : https://docs.python.org/3/reference/expressions.html
 
For Apache Spark Installation : https://spark.apache.org/downloads.html

Open Jupyter Notebook from Spark (PySpark) : https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f

